{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from dataget import data\n",
    "import tfinterface as ti\n",
    "import sonnet as snt\n",
    "import tensorflow as tf\n",
    "\n",
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = data(\"mnist\").get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "traning_set = dataset.complete_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(snt.AbstractModule):\n",
    "    \n",
    "    def _build(self, inputs):\n",
    "        \n",
    "        net = inputs[\"image\"]; print(net)\n",
    "        training = inputs[\"mode\"] == tf.estimator.ModeKeys.TRAIN\n",
    "        \n",
    "        net = ti.layers.conv2d_batch_norm(net, 16, [5, 5], strides = 2, activation = tf.nn.elu, padding = \"same\", batch_norm = dict(training = training)); print(net)\n",
    "        net = ti.layers.conv2d_batch_norm(net, 32, [3, 3], strides = 2, activation = tf.nn.elu, padding = \"valid\", batch_norm = dict(training = training)); print(net)\n",
    "        net = ti.layers.conv2d_batch_norm(net, 64, [3, 3], strides = 2, activation = tf.nn.elu, padding = \"valid\", batch_norm = dict(training = training)); print(net)\n",
    "        net = ti.layers.conv2d_batch_norm(net, 128, [2, 2], strides = 2, activation = tf.nn.elu, padding = \"same\", batch_norm = dict(training = training)); print(net)\n",
    "\n",
    "        \n",
    "        net = tf.contrib.layers.flatten(net); print(net)\n",
    "        \n",
    "        net = ti.layers.dense_batch_norm(net, 64, activation = tf.nn.elu, batch_norm = dict(training = training)); print(net)\n",
    "        net = logits = tf.layers.dense(net, 1, activation = None); print(net)\n",
    "#         net = tf.nn.sigmoid(net); print(net)\n",
    "        \n",
    "        return logits\n",
    "    \n",
    "    \n",
    "class Generator(snt.AbstractModule):\n",
    "    \n",
    "    def _build(self, inputs):\n",
    "        \n",
    "        \n",
    "        training = inputs[\"mode\"] == tf.estimator.ModeKeys.TRAIN\n",
    "        net = inputs[\"embedding\"]; print(net)\n",
    "        \n",
    "        net = ti.layers.conv2d_transpose_batch_norm(net, 512, [2, 2], strides = 1, activation = tf.nn.elu, \n",
    "                                                    padding = \"valid\", batch_norm = dict(training = training)); print(net)\n",
    "        net = ti.layers.conv2d_transpose_batch_norm(net, 256, [3, 3], strides = 2, activation = tf.nn.elu, \n",
    "                                                    padding = \"valid\", batch_norm = dict(training = training)); print(net)\n",
    "        net = ti.layers.conv2d_transpose_batch_norm(net, 128, [3, 3], strides = 2, activation = tf.nn.elu, \n",
    "                                                    padding = \"same\", batch_norm = dict(training = training)); print(net)\n",
    "        net = ti.layers.conv2d_transpose_batch_norm(net, 1, [3, 3], strides = 2, activation = tf.nn.tanh, \n",
    "                                                    padding = \"same\", batch_norm = dict(training = training)); print(net)\n",
    "        \n",
    "        net = (net + 1.0) / 2.0\n",
    "        \n",
    "        \n",
    "        return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator\n",
      "Tensor(\"input_layer_39:0\", shape=(?, 28, 28, 1), dtype=float32)\n",
      "Tensor(\"discriminator_19/Conv2dBatchNorm/Elu:0\", shape=(?, 14, 14, 16), dtype=float32)\n",
      "Tensor(\"discriminator_19/Conv2dBatchNorm_1/Elu:0\", shape=(?, 6, 6, 32), dtype=float32)\n",
      "Tensor(\"discriminator_19/Conv2dBatchNorm_2/Elu:0\", shape=(?, 2, 2, 64), dtype=float32)\n",
      "Tensor(\"discriminator_19/Conv2dBatchNorm_3/Elu:0\", shape=(?, 1, 1, 128), dtype=float32)\n",
      "Tensor(\"discriminator_19/Flatten/flatten/Reshape:0\", shape=(?, 128), dtype=float32)\n",
      "Tensor(\"discriminator_19/DenseBatchNorm/Elu:0\", shape=(?, 64), dtype=float32)\n",
      "Tensor(\"discriminator_19/dense/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "Generator\n",
      "Tensor(\"input_layer_40:0\", shape=(?, 2, 2, 25), dtype=float32)\n",
      "Tensor(\"generator_19/Conv2dTransposeBatchNorm/Elu:0\", shape=(?, 3, 3, 512), dtype=float32)\n",
      "Tensor(\"generator_19/Conv2dTransposeBatchNorm_1/Elu:0\", shape=(?, 7, 7, 256), dtype=float32)\n",
      "Tensor(\"generator_19/Conv2dTransposeBatchNorm_2/Elu:0\", shape=(?, 14, 14, 128), dtype=float32)\n",
      "Tensor(\"generator_19/Conv2dTransposeBatchNorm_3/Elu:0\", shape=(?, 28, 28, 64), dtype=float32)\n",
      "Tensor(\"generator_19/conv2d/Tanh:0\", shape=(?, 28, 28, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "inputs = dict(\n",
    "    image = tf.layers.Input(shape=(28, 28, 1)),\n",
    "    embedding = tf.layers.Input(shape=(2, 2, 25)),\n",
    "    mode = tf.estimator.ModeKeys.TRAIN,\n",
    ")\n",
    "\n",
    "D = Discriminator(name = \"discriminator\")\n",
    "G = Generator(name = \"generator\")\n",
    "\n",
    "print(\"Discriminator\")\n",
    "\n",
    "d = D(inputs)\n",
    "print(\"\")\n",
    "print(\"Generator\")\n",
    "g = G(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model_fn(features, labels, mode, params):\n",
    "    \n",
    "    image = labels[\"image\"]\n",
    "    embedding = features[\"embedding\"]\n",
    "    \n",
    "    D = Discriminator(name = \"discriminator\")\n",
    "    G = Generator(name = \"generator\")\n",
    "    \n",
    "    \n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        net = G(dict(\n",
    "            embedding = embedding\n",
    "        ))\n",
    "        \n",
    "        return tf.estimator.EstimatorSpec(\n",
    "            mode = mode,\n",
    "            predictions = net\n",
    "        )\n",
    "    \n",
    "    \n",
    "    \n",
    "    # d_loss_real\n",
    "    d_logits_real = D(dict(\n",
    "        image = image\n",
    "    ))\n",
    "    \n",
    "    is_real = tf.ones_like(real_d_logits, dtype=tf.float32)\n",
    "    \n",
    "    d_loss_real = tf.losses.sigmoid_cross_entropy(is_real, d_logits_real)\n",
    "    d_loss_real = tf.reduce_mean(d_loss_real)\n",
    "    \n",
    "    # d_loss_fake\n",
    "    fake_image = G(dict(\n",
    "        embedding = embedding\n",
    "    ))\n",
    "    \n",
    "    d_logits_fake = D(dict(\n",
    "        image = fake_image\n",
    "    ))\n",
    "    \n",
    "    is_fake = tf.zeros_like(d_logits_fake, dtype=tf.float32)\n",
    "    \n",
    "    d_loss_fake = tf.losses.sigmoid_cross_entropy(is_fake, d_logits_fake)\n",
    "    d_loss_fake = tf.reduce_mean(d_loss_fake)\n",
    "    \n",
    "    # d_loss\n",
    "    d_loss = d_loss_real + d_loss_fake\n",
    "    \n",
    "    # g_loss\n",
    "    g_loss = tf.losses.sigmoid_cross_entropy(is_real, d_logits_fake)\n",
    "    \n",
    "    # global loss\n",
    "    loss = g_loss + d_loss\n",
    "    \n",
    "    if mode == tf.estimator.ModeKeys.EVAL:\n",
    "        return tf.estimator.EstimatorSpec(\n",
    "            mode = mode,\n",
    "            predictions = net,\n",
    "            loss = loss\n",
    "        )\n",
    "    \n",
    "    \n",
    "    #updates\n",
    "    \n",
    "    d_update = tf.train.AdamOptimizer(params[\"learning_rate\"]).minimize(d_loss, \n",
    "                                                                        global_step = params[\"global_step\"])\n",
    "    \n",
    "    g_update = tf.train.AdamOptimizer(params[\"learning_rate\"]).minimize(g_loss,\n",
    "                                                                        global_step = params[\"global_step\"])\n",
    "    \n",
    "    update = tf.group(d_update, g_update)\n",
    "    \n",
    "    return tf.estimator.EstimatorSpec(\n",
    "        mode = mode,\n",
    "        predictions = net,\n",
    "        loss = loss,\n",
    "        train_op = update\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 2, 25)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
